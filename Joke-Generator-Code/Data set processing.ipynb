{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cocalc": {
     "outputs": {
      "1": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": "What type of joke would you like to generate?"
       },
       "output_type": "stream"
      }
     }
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /projects/aebc210b-e912-4df\n",
      "[nltk_data]     7-91ea-37e0f8451ece/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /projects/aebc210b-e912-4df7-\n",
      "[nltk_data]     91ea-37e0f8451ece/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to /project\n",
      "[nltk_data]     s/aebc210b-e912-4df7-91ea-37e0f8451ece/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /projects/aebc210b-e912-4\n",
      "[nltk_data]     df7-91ea-37e0f8451ece/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "What type of joke would you like to generate? "
    }
   ],
   "source": [
    "from aitextgen import aitextgen\n",
    "from aitextgen.TokenDataset import TokenDataset\n",
    "from aitextgen.tokenizers import train_tokenizer\n",
    "from aitextgen.utils import GPT2ConfigCPU\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import urllib\n",
    "import bs4 as bs\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#jokes file from the rating jokes dataset:\n",
    "generic_joke_file = \"jokes.csv\"\n",
    "#dad jokes file:\n",
    "dad_joke_file = \"reddit_dadjokes.csv\"\n",
    "#currently only has the text for the bar jokes\n",
    "bar_joke_url = \t\"https://www.grammarbook.com/blog/definitions/walks-into-a-bar/\"\n",
    "\n",
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "source = urllib.request.urlopen(bar_joke_url).read()\n",
    "soup = bs.BeautifulSoup(source,\"html.parser\")\n",
    "\n",
    "#all of the data would be a string so it can go in the list below\n",
    "generic_joke_text = \"\"\n",
    "bar_joke_text = \"\"\n",
    "dad_joke_text = \"\"\n",
    "joke_type = [generic_joke_text,dad_joke_text,bar_joke_text]\n",
    "\n",
    "\n",
    "for i in range(len(joke_type)):\n",
    "    for paragraph in soup.find_all('p'):\n",
    "        joke_type[i] += paragraph.text\n",
    "        joke_type[i] = re.sub(r'\\[[0-9]*\\]',' ',joke_type[i])\n",
    "        joke_type[i] = joke_type[i].lower()\n",
    "        joke_type[i] = re.sub(r'\\W^.?!',' ',joke_type[i])\n",
    "        joke_type[i] = re.sub(r'\\d',' ',joke_type[i])\n",
    "        joke_type[i] = re.sub(r'\\s+',' ',joke_type[i])\n",
    "\n",
    "#just putting this here so we can control which set is used - this is temporary\n",
    "chosen_type = input(\"What type of joke would you like to generate?\")\n",
    "chosen_type = chosen_type.lower()\n",
    "\n",
    "\n",
    "\n",
    "tokens = word_tokenize(joke_type[0])\n",
    "\n",
    "print(joke_type[1][:100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "nlp_env",
   "resource_dir": "/projects/aebc210b-e912-4df7-91ea-37e0f8451ece/.local/share/jupyter/kernels/nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}